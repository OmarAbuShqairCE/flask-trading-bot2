from flask import Flask, render_template, jsonify, request
from flask_cors import CORS
import requests
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json
import threading
import time
from datetime import timezone
from dotenv import load_dotenv
import os
import pickle
import joblib
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Dense, LSTM, Dropout, Conv1D, MaxPooling1D, Flatten
from tensorflow.keras.optimizers import Adam
import cv2
from PIL import Image
import io
import base64
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.cluster import KMeans
import warnings
warnings.filterwarnings('ignore')


class AITradingSystem:
    """Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù„Ù„ØªØ¯Ø§ÙˆÙ„"""
    
    def __init__(self):
        self.ml_models = {}
        self.neural_models = {}
        self.time_series_models = {}
        self.reinforcement_models = {}
        self.scalers = {}
        self.label_encoders = {}
        self.performance_history = []
        self.model_metrics = {}
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
        self.model_config = {
            'random_forest': {'n_estimators': 100, 'max_depth': 10},
            'gradient_boosting': {'n_estimators': 100, 'learning_rate': 0.1},
            'neural_network': {'hidden_layers': (100, 50), 'activation': 'relu'},
            'lstm': {'units': 50, 'dropout': 0.2, 'epochs': 50},
            'cnn': {'filters': 32, 'kernel_size': 3, 'epochs': 30}
        }
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©
        self.load_saved_models()
    
    def load_saved_models(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©"""
        try:
            if os.path.exists('ai_models.pkl'):
                with open('ai_models.pkl', 'rb') as f:
                    saved_data = pickle.load(f)
                    self.ml_models = saved_data.get('ml_models', {})
                    self.neural_models = saved_data.get('neural_models', {})
                    self.scalers = saved_data.get('scalers', {})
                    self.model_metrics = saved_data.get('metrics', {})
                print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø© Ø¨Ù†Ø¬Ø§Ø­")
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {e}")
    
    def save_models(self):
        """Ø­ÙØ¸ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨Ø©"""
        try:
            save_data = {
                'ml_models': self.ml_models,
                'neural_models': self.neural_models,
                'scalers': self.scalers,
                'metrics': self.model_metrics
            }
            with open('ai_models.pkl', 'wb') as f:
                pickle.dump(save_data, f)
            print("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ù†Ø¬Ø§Ø­")
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {e}")
    
    def prepare_training_data(self, price_data, indicators_data):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
        try:
            # Ø¯Ù…Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø¹Ø§Ø± ÙˆØ§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
            features = []
            labels = []
            
            for i in range(len(price_data) - 1):
                feature_vector = []
                
                # Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø¹Ø§Ø±
                current_price = price_data[i]
                next_price = price_data[i + 1]
                
                feature_vector.extend([
                    current_price['open'],
                    current_price['high'],
                    current_price['low'],
                    current_price['close']
                ])
                
                # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
                for indicator_name, indicator_data in indicators_data.items():
                    if indicator_data and len(indicator_data) > i:
                        indicator_value = self._extract_indicator_value(indicator_data[i])
                        if indicator_value is not None:
                            feature_vector.append(indicator_value)
                        else:
                            feature_vector.append(0)
                    else:
                        feature_vector.append(0)
                
                # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¹Ù„Ø§Ù…Ø© (Ø§Ù„Ù†ØªÙŠØ¬Ø©)
                price_change = (next_price['close'] - current_price['close']) / current_price['close']
                if price_change > 0.001:  # Ø§Ø±ØªÙØ§Ø¹ Ø£ÙƒØ«Ø± Ù…Ù† 0.1%
                    label = 1  # BUY
                elif price_change < -0.001:  # Ø§Ù†Ø®ÙØ§Ø¶ Ø£ÙƒØ«Ø± Ù…Ù† 0.1%
                    label = 0  # SELL
                else:
                    label = 2  # HOLD
                
                features.append(feature_vector)
                labels.append(label)
            
            return np.array(features), np.array(labels)
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {e}")
            return None, None
    
    def _extract_indicator_value(self, indicator_data):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø¤Ø´Ø±"""
        if isinstance(indicator_data, dict):
            for key in ['value', 'close', 'sma', 'ema', 'rsi', 'macd']:
                if key in indicator_data:
                    try:
                        return float(indicator_data[key])
                    except:
                        continue
        return None
    
    def train_ml_models(self, features, labels):
        """ØªØ¯Ø±ÙŠØ¨ Ù†Ù…Ø§Ø°Ø¬ Machine Learning"""
        try:
            # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            X_train, X_test, y_train, y_test = train_test_split(
                features, labels, test_size=0.2, random_state=42
            )
            
            # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            self.scalers['main'] = scaler
            
            # ØªØ¯Ø±ÙŠØ¨ Random Forest
            rf_model = RandomForestClassifier(**self.model_config['random_forest'])
            rf_model.fit(X_train_scaled, y_train)
            rf_pred = rf_model.predict(X_test_scaled)
            rf_accuracy = accuracy_score(y_test, rf_pred)
            self.ml_models['random_forest'] = rf_model
            self.model_metrics['random_forest'] = {'accuracy': rf_accuracy}
            
            # ØªØ¯Ø±ÙŠØ¨ Gradient Boosting
            gb_model = GradientBoostingClassifier(**self.model_config['gradient_boosting'])
            gb_model.fit(X_train_scaled, y_train)
            gb_pred = gb_model.predict(X_test_scaled)
            gb_accuracy = accuracy_score(y_test, gb_pred)
            self.ml_models['gradient_boosting'] = gb_model
            self.model_metrics['gradient_boosting'] = {'accuracy': gb_accuracy}
            
            # ØªØ¯Ø±ÙŠØ¨ Neural Network
            nn_model = MLPClassifier(**self.model_config['neural_network'])
            nn_model.fit(X_train_scaled, y_train)
            nn_pred = nn_model.predict(X_test_scaled)
            nn_accuracy = accuracy_score(y_test, nn_pred)
            self.ml_models['neural_network'] = nn_model
            self.model_metrics['neural_network'] = {'accuracy': nn_accuracy}
            
            print(f"âœ… ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ù†Ù…Ø§Ø°Ø¬ ML - RF: {rf_accuracy:.3f}, GB: {gb_accuracy:.3f}, NN: {nn_accuracy:.3f}")
            return True
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…Ø§Ø°Ø¬ ML: {e}")
            return False
    
    def train_lstm_model(self, features, labels):
        """ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ LSTM Ù„Ù„Ø³Ù„Ø§Ø³Ù„ Ø§Ù„Ø²Ù…Ù†ÙŠØ©"""
        try:
            # Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ÙƒÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù€ LSTM
            sequence_length = 10
            X_lstm, y_lstm = [], []
            
            for i in range(sequence_length, len(features)):
                X_lstm.append(features[i-sequence_length:i])
                y_lstm.append(labels[i])
            
            X_lstm = np.array(X_lstm)
            y_lstm = np.array(y_lstm)
            
            # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            X_train, X_test, y_train, y_test = train_test_split(
                X_lstm, y_lstm, test_size=0.2, random_state=42
            )
            
            # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            scaler_lstm = StandardScaler()
            X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])
            X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])
            X_train_scaled = scaler_lstm.fit_transform(X_train_reshaped)
            X_test_scaled = scaler_lstm.transform(X_test_reshaped)
            X_train_scaled = X_train_scaled.reshape(X_train.shape)
            X_test_scaled = X_test_scaled.reshape(X_test.shape)
            
            self.scalers['lstm'] = scaler_lstm
            
            # Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ LSTM
            model = Sequential([
                LSTM(50, return_sequences=True, input_shape=(sequence_length, X_train.shape[-1])),
                Dropout(0.2),
                LSTM(50, return_sequences=False),
                Dropout(0.2),
                Dense(25, activation='relu'),
                Dense(3, activation='softmax')
            ])
            
            model.compile(optimizer=Adam(learning_rate=0.001), 
                         loss='sparse_categorical_crossentropy', 
                         metrics=['accuracy'])
            
            # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            model.fit(X_train_scaled, y_train, 
                     epochs=self.model_config['lstm']['epochs'], 
                     batch_size=32, 
                     validation_data=(X_test_scaled, y_test),
                     verbose=0)
            
            # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            lstm_loss, lstm_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)
            self.neural_models['lstm'] = model
            self.model_metrics['lstm'] = {'accuracy': lstm_accuracy, 'loss': lstm_loss}
            
            print(f"âœ… ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ LSTM - Ø¯Ù‚Ø©: {lstm_accuracy:.3f}")
            return True
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ LSTM: {e}")
            return False
    
    def train_cnn_model(self, features, labels):
        """ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ CNN Ù„Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ø­Ø§Ø³ÙˆØ¨ÙŠØ©"""
        try:
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù€ CNN
            sequence_length = 20
            X_cnn, y_cnn = [], []
            
            for i in range(sequence_length, len(features)):
                X_cnn.append(features[i-sequence_length:i])
                y_cnn.append(labels[i])
            
            X_cnn = np.array(X_cnn)
            y_cnn = np.array(y_cnn)
            
            # Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ÙƒÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù€ CNN
            X_cnn = X_cnn.reshape(X_cnn.shape[0], X_cnn.shape[1], 1)
            
            # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            X_train, X_test, y_train, y_test = train_test_split(
                X_cnn, y_cnn, test_size=0.2, random_state=42
            )
            
            # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            scaler_cnn = StandardScaler()
            X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])
            X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])
            X_train_scaled = scaler_cnn.fit_transform(X_train_reshaped)
            X_test_scaled = scaler_cnn.transform(X_test_reshaped)
            X_train_scaled = X_train_scaled.reshape(X_train.shape)
            X_test_scaled = X_test_scaled.reshape(X_test.shape)
            
            self.scalers['cnn'] = scaler_cnn
            
            # Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ CNN
            model = Sequential([
                Conv1D(32, 3, activation='relu', input_shape=(sequence_length, 1)),
                MaxPooling1D(2),
                Conv1D(64, 3, activation='relu'),
                MaxPooling1D(2),
                Flatten(),
                Dense(50, activation='relu'),
                Dropout(0.2),
                Dense(3, activation='softmax')
            ])
            
            model.compile(optimizer=Adam(learning_rate=0.001), 
                         loss='sparse_categorical_crossentropy', 
                         metrics=['accuracy'])
            
            # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            model.fit(X_train_scaled, y_train, 
                     epochs=self.model_config['cnn']['epochs'], 
                     batch_size=32, 
                     validation_data=(X_test_scaled, y_test),
                     verbose=0)
            
            # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            cnn_loss, cnn_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)
            self.neural_models['cnn'] = model
            self.model_metrics['cnn'] = {'accuracy': cnn_accuracy, 'loss': cnn_loss}
            
            print(f"âœ… ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ CNN - Ø¯Ù‚Ø©: {cnn_accuracy:.3f}")
            return True
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ CNN: {e}")
            return False
    
    def predict_with_ensemble(self, features):
        """Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
        try:
            predictions = []
            probabilities = []
            
            # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if 'main' in self.scalers:
                features_scaled = self.scalers['main'].transform([features])
            else:
                features_scaled = [features]
            
            # ØªÙ†Ø¨Ø¤Ø§Øª Ù†Ù…Ø§Ø°Ø¬ ML
            for model_name, model in self.ml_models.items():
                if hasattr(model, 'predict_proba'):
                    pred_proba = model.predict_proba(features_scaled)[0]
                    pred = model.predict(features_scaled)[0]
                    predictions.append(pred)
                    probabilities.append(pred_proba)
            
            # ØªÙ†Ø¨Ø¤Ø§Øª Ù†Ù…Ø§Ø°Ø¬ Neural Networks
            for model_name, model in self.neural_models.items():
                if model_name == 'lstm':
                    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª LSTM
                    sequence_length = 10
                    if len(features) >= sequence_length:
                        lstm_input = np.array([features[-sequence_length:]])
                        if 'lstm' in self.scalers:
                            lstm_input_reshaped = lstm_input.reshape(-1, lstm_input.shape[-1])
                            lstm_input_scaled = self.scalers['lstm'].transform(lstm_input_reshaped)
                            lstm_input_scaled = lstm_input_scaled.reshape(lstm_input.shape)
                        else:
                            lstm_input_scaled = lstm_input
                        
                        pred_proba = model.predict(lstm_input_scaled, verbose=0)[0]
                        pred = np.argmax(pred_proba)
                        predictions.append(pred)
                        probabilities.append(pred_proba)
                
                elif model_name == 'cnn':
                    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª CNN
                    sequence_length = 20
                    if len(features) >= sequence_length:
                        cnn_input = np.array([features[-sequence_length:]])
                        cnn_input = cnn_input.reshape(cnn_input.shape[0], cnn_input.shape[1], 1)
                        
                        if 'cnn' in self.scalers:
                            cnn_input_reshaped = cnn_input.reshape(-1, cnn_input.shape[-1])
                            cnn_input_scaled = self.scalers['cnn'].transform(cnn_input_reshaped)
                            cnn_input_scaled = cnn_input_scaled.reshape(cnn_input.shape)
                        else:
                            cnn_input_scaled = cnn_input
                        
                        pred_proba = model.predict(cnn_input_scaled, verbose=0)[0]
                        pred = np.argmax(pred_proba)
                        predictions.append(pred)
                        probabilities.append(pred_proba)
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø±Ø¬Ø­ Ù„Ù„ØªÙ†Ø¨Ø¤Ø§Øª
            if probabilities:
                avg_probabilities = np.mean(probabilities, axis=0)
                final_prediction = np.argmax(avg_probabilities)
                confidence = np.max(avg_probabilities) * 100
                
                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆÙ‚Ø¹ Ø¥Ù„Ù‰ Ù†Øµ
                signal_map = {0: 'SELL', 1: 'BUY', 2: 'HOLD'}
                signal = signal_map.get(final_prediction, 'HOLD')
                
                return {
                    'signal': signal,
                    'confidence': round(confidence, 2),
                    'probabilities': {
                        'BUY': round(avg_probabilities[1] * 100, 2),
                        'SELL': round(avg_probabilities[0] * 100, 2),
                        'HOLD': round(avg_probabilities[2] * 100, 2)
                    },
                    'model_predictions': len(predictions),
                    'ensemble_used': True
                }
            else:
                return {
                    'signal': 'HOLD',
                    'confidence': 0,
                    'probabilities': {'BUY': 0, 'SELL': 0, 'HOLD': 100},
                    'model_predictions': 0,
                    'ensemble_used': False
                }
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤: {e}")
            return {
                'signal': 'HOLD',
                'confidence': 0,
                'probabilities': {'BUY': 0, 'SELL': 0, 'HOLD': 100},
                'model_predictions': 0,
                'ensemble_used': False
            }
    
    def analyze_chart_patterns(self, price_data):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· ÙÙŠ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ø­Ø§Ø³ÙˆØ¨ÙŠØ©"""
        try:
            # Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ
            plt.figure(figsize=(10, 6))
            prices = [p['close'] for p in price_data[-50:]]  # Ø¢Ø®Ø± 50 Ù†Ù‚Ø·Ø©
            plt.plot(prices)
            plt.title('Price Chart Analysis')
            plt.xlabel('Time')
            plt.ylabel('Price')
            
            # Ø­ÙØ¸ Ø§Ù„Ø±Ø³Ù… ÙƒØµÙˆØ±Ø©
            img_buffer = io.BytesIO()
            plt.savefig(img_buffer, format='png', dpi=100, bbox_inches='tight')
            img_buffer.seek(0)
            plt.close()
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØµÙˆØ±Ø© OpenCV
            img_data = img_buffer.getvalue()
            nparr = np.frombuffer(img_data, np.uint8)
            img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø·
            patterns = self._detect_chart_patterns(img)
            
            return {
                'patterns_detected': patterns,
                'chart_analysis': True
            }
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø·: {e}")
            return {
                'patterns_detected': [],
                'chart_analysis': False
            }
    
    def _detect_chart_patterns(self, img):
        """ÙƒØ´Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø· ÙÙŠ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ"""
        try:
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØªØ¯Ø±Ø¬ Ø±Ù…Ø§Ø¯ÙŠ
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            
            # ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù
            edges = cv2.Canny(gray, 50, 150)
            
            # ÙƒØ´Ù Ø§Ù„Ø®Ø·ÙˆØ·
            lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=50, minLineLength=30, maxLineGap=10)
            
            patterns = []
            if lines is not None:
                # ØªØ­Ù„ÙŠÙ„ Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø®Ø·ÙˆØ·
                upward_lines = 0
                downward_lines = 0
                
                for line in lines:
                    x1, y1, x2, y2 = line[0]
                    angle = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi
                    
                    if -45 < angle < 45:  # Ø®Ø· Ø£ÙÙ‚ÙŠ
                        continue
                    elif angle > 0:  # Ø®Ø· ØµØ§Ø¹Ø¯
                        upward_lines += 1
                    else:  # Ø®Ø· Ù‡Ø§Ø¨Ø·
                        downward_lines += 1
                
                # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ù†Ù…Ø§Ø·
                if upward_lines > downward_lines * 1.5:
                    patterns.append('Uptrend')
                elif downward_lines > upward_lines * 1.5:
                    patterns.append('Downtrend')
                else:
                    patterns.append('Sideways')
            
            return patterns
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙƒØ´Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø·: {e}")
            return []
    
    def reinforcement_learning_update(self, action, reward, state):
        """ØªØ­Ø¯ÙŠØ« Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø¹Ø²Ø²"""
        try:
            # ØªØ·Ø¨ÙŠÙ‚ Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Q-Learning Ù…Ø¨Ø³Ø·Ø©
            if not hasattr(self, 'q_table'):
                self.q_table = {}
            
            state_key = str(state)
            if state_key not in self.q_table:
                self.q_table[state_key] = {'BUY': 0, 'SELL': 0, 'HOLD': 0}
            
            # ØªØ­Ø¯ÙŠØ« Ù‚ÙŠÙ…Ø© Q
            learning_rate = 0.1
            discount_factor = 0.9
            
            old_value = self.q_table[state_key][action]
            self.q_table[state_key][action] = old_value + learning_rate * (reward - old_value)
            
            return True
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø¹Ø²Ø²: {e}")
            return False
    
    def get_reinforcement_prediction(self, state):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙ†Ø¨Ø¤ Ù…Ù† Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø¹Ø²Ø²"""
        try:
            state_key = str(state)
            if state_key in self.q_table:
                q_values = self.q_table[state_key]
                best_action = max(q_values, key=q_values.get)
                confidence = abs(q_values[best_action]) / 10  # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù†Ø³Ø¨Ø© Ù…Ø¦ÙˆÙŠØ©
                return {
                    'signal': best_action,
                    'confidence': min(confidence * 100, 100),
                    'q_values': q_values
                }
            else:
                return {
                    'signal': 'HOLD',
                    'confidence': 0,
                    'q_values': {'BUY': 0, 'SELL': 0, 'HOLD': 0}
                }
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¨Ø¤ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø¹Ø²Ø²: {e}")
            return {
                'signal': 'HOLD',
                'confidence': 0,
                'q_values': {'BUY': 0, 'SELL': 0, 'HOLD': 0}
            }
    
    def get_performance_metrics(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        return {
            'model_metrics': self.model_metrics,
            'performance_history': self.performance_history[-10:],  # Ø¢Ø®Ø± 10 Ù‚ÙŠØ§Ø³Ø§Øª
            'total_models': len(self.ml_models) + len(self.neural_models),
            'models_loaded': len(self.ml_models) > 0 or len(self.neural_models) > 0
        }


class TradingAnalyzer:
    def __init__(self, api_key=None):
        self.api_key = api_key or API_KEY
        self.base_url = "https://api.twelvedata.com/time_series"
        self.is_running = False
        self.analysis_thread = None
        self.latest_results = {}
        
        # Ø¥Ø¶Ø§ÙØ© Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
        self.ai_system = AITradingSystem()
        self.training_data = []
        self.ai_enabled = True
        
        # Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø·Ù„Ø¨Ø§Øª
        self.api_requests_count = 0
        self.api_requests_limit = 8  # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø·Ù„Ø¨Ø§Øª ÙÙŠ Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©
        self.last_reset_time = datetime.now()
        
        # Ø¬Ù…ÙŠØ¹ Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©
        self.available_pairs = [
            'EUR/USD', 'GBP/USD', 'USD/JPY', 'AUD/USD', 'USD/CHF',
            'EUR/GBP', 'EUR/JPY', 'GBP/JPY', 'AUD/JPY', 'NZD/USD',
            'USD/CAD', 'EUR/AUD', 'GBP/AUD', 'EUR/CAD', 'GBP/CAD',
            'AUD/CAD', 'NZD/JPY', 'CHF/JPY', 'EUR/NZD', 'GBP/NZD'
        ]
        
        # Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª
        self.available_indicators = {
            # Trend Indicators (Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø§ØªØ¬Ø§Ù‡)
            'trend': {
                'sma': 'Simple Moving Average',
                'ema': 'Exponential Moving Average', 
                'wma': 'Weighted Moving Average',
                'dema': 'Double Exponential Moving Average',
                'tema': 'Triple Exponential Moving Average',
                'kama': 'Kaufman Adaptive Moving Average',
                'hma': 'Hull Moving Average',
                't3': 'T3 Moving Average'
            },
            # Momentum Indicators (Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø²Ø®Ù…)
            'momentum': {
                'rsi': 'Relative Strength Index',
                'stoch': 'Stochastic Oscillator',
                'stochrsi': 'Stochastic RSI',
                'willr': 'Williams %R',
                'macd': 'MACD',
                'ppo': 'Percentage Price Oscillator',
                'adx': 'Average Directional Index',
                'cci': 'Commodity Channel Index',
                'mom': 'Momentum',
                'roc': 'Rate of Change'
            },
            # Volatility Indicators (Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªØ°Ø¨Ø°Ø¨)
            'volatility': {
                'bbands': 'Bollinger Bands',
                'atr': 'Average True Range',
                'stdev': 'Standard Deviation',
                'donchian': 'Donchian Channels'
            },
            # Volume Indicators (Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø­Ø¬Ù…)
            'volume': {
                'obv': 'On Balance Volume',
                'cmf': 'Chaikin Money Flow',
                'ad': 'Accumulation/Distribution',
                'mfi': 'Money Flow Index',
                'emv': 'Ease of Movement',
                'fi': 'Force Index'
            },
            # Price Indicators (Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø³Ø¹Ø±)
            'price': {
                'avgprice': 'Average Price',
                'medprice': 'Median Price',
                'typprice': 'Typical Price',
                'wcprice': 'Weighted Close Price'
            },
            # Misc / Other Indicators (Ù…Ø¤Ø´Ø±Ø§Øª Ø£Ø®Ø±Ù‰)
            'misc': {
                'sar': 'Parabolic SAR',
                'ultosc': 'Ultimate Oscillator',
                'tsi': 'True Strength Index'
            }
        }
    
    def set_api_key(self, api_key):
        """ØªØ¹ÙŠÙŠÙ† Ù…ÙØªØ§Ø­ API"""
        self.api_key = api_key
    
    def _check_api_limit(self):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¯ Ø§Ù„Ø·Ù„Ø¨Ø§Øª"""
        current_time = datetime.now()
        
        # Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø¹Ø¯Ø§Ø¯ ÙƒÙ„ Ø¯Ù‚ÙŠÙ‚Ø©
        if (current_time - self.last_reset_time).seconds >= 60:
            self.api_requests_count = 0
            self.last_reset_time = current_time
        
        return self.api_requests_count < self.api_requests_limit
    
    def _increment_api_count(self):
        """Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø·Ù„Ø¨Ø§Øª"""
        self.api_requests_count += 1
    
    def get_api_status(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© API"""
        current_time = datetime.now()
        time_remaining = 60 - (current_time - self.last_reset_time).seconds
        
        return {
            'requests_used': self.api_requests_count,
            'requests_limit': self.api_requests_limit,
            'requests_remaining': self.api_requests_limit - self.api_requests_count,
            'time_remaining': max(0, time_remaining),
            'can_make_request': self._check_api_limit()
        }
    
   
    #---------------------------------------------------
    def fetch_indicator_data(self, pair, indicator, interval='1min', **params):
        """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¤Ø´Ø± Ù…Ù† API TwelveData"""
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¯ Ø§Ù„Ø·Ù„Ø¨Ø§Øª
            if not self._check_api_limit():
                print(f"ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù…Ù† Ø§Ù„Ø·Ù„Ø¨Ø§Øª ({self.api_requests_limit})")
                return None
            
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
            api_params = {
                'symbol': pair,
                'interval': interval,
                'apikey': self.api_key,
                **params
            }
            
            # Ø¨Ù†Ø§Ø¡ URL Ø§Ù„Ù…Ø¤Ø´Ø±
            indicator_url = f"https://api.twelvedata.com/{indicator}"
            
            # Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø·Ù„Ø¨Ø§Øª
            self._increment_api_count()
            print(f"Ø·Ù„Ø¨ API #{self.api_requests_count}/{self.api_requests_limit}: {indicator} Ù„Ù€ {pair}")
            
            response = requests.get(indicator_url, params=api_params, timeout=10)
            
            if response.status_code != 200:
                print(f"Ø®Ø·Ø£ HTTP Ø¹Ù†Ø¯ Ø¬Ù„Ø¨ {indicator} Ù„Ù€ {pair}: Ø­Ø§Ù„Ø© {response.status_code}")
                return None
            
            data = response.json()
            
            # ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø®Ø·Ø£ ÙÙŠ API
            if 'status' in data and data['status'] == 'error':
                error_msg = data.get('message', 'Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')
                print(f"Ø®Ø·Ø£ Ù…Ù† API Ø¹Ù†Ø¯ Ø¬Ù„Ø¨ {indicator} Ù„Ù€ {pair}: {error_msg}")
                
                # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø®Ø·Ø£ Ø¨Ø³Ø¨Ø¨ Ø§Ø³ØªÙ†ÙØ§Ø¯ Ø§Ù„Ø±ØµÙŠØ¯ØŒ Ø§Ù†ØªØ¸Ø± Ø¯Ù‚ÙŠÙ‚Ø©
                if 'API credits' in error_msg or 'limit' in error_msg:
                    print("Ø§Ù†ØªØ¸Ø§Ø± 60 Ø«Ø§Ù†ÙŠØ© Ù„ØªØ¬Ù†Ø¨ Ø§Ø³ØªÙ†ÙØ§Ø¯ Ø§Ù„Ø±ØµÙŠØ¯...")
                    import time
                    time.sleep(60)
                
                return None
            
            if 'values' not in data or not data['values']:
                print(f"Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù€ {indicator} Ù„Ù€ {pair}")
                return None
            
            # Ø·Ø¨Ø§Ø¹Ø© Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ­Ù‚Ù‚
            if data['values'] and len(data['values']) > 0:
                print(f"Ù‡ÙŠÙƒÙ„ Ø¨ÙŠØ§Ù†Ø§Øª {indicator}: {list(data['values'][0].keys())}")
            
            return data['values']
            
        except requests.exceptions.RequestException as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¹Ù†Ø¯ Ø¬Ù„Ø¨ {indicator} Ù„Ù€ {pair}: {str(e)}")
            return None
        except json.JSONDecodeError as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ ÙÙƒ JSON Ø¹Ù†Ø¯ Ø¬Ù„Ø¨ {indicator} Ù„Ù€ {pair}: {str(e)}")
            return None
        except Exception as e:
            print(f"Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø¹Ù†Ø¯ Ø¬Ù„Ø¨ {indicator} Ù„Ù€ {pair}: {str(e)}")
            return None

    def fetch_price_data(self, pair, interval='1min', outputsize=250):
        """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©"""
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¯ Ø§Ù„Ø·Ù„Ø¨Ø§Øª
            if not self._check_api_limit():
                print(f"ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù…Ù† Ø§Ù„Ø·Ù„Ø¨Ø§Øª ({self.api_requests_limit})")
                return None
            
            params = {
                'symbol': pair,
                'interval': interval,
                'apikey': self.api_key,
                'outputsize': outputsize
            }
            
            # Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø·Ù„Ø¨Ø§Øª
            self._increment_api_count()
            print(f"Ø·Ù„Ø¨ API #{self.api_requests_count}/{self.api_requests_limit}: Ø£Ø³Ø¹Ø§Ø± {pair}")
        
            response = requests.get(self.base_url, params=params, timeout=10)
        
            if response.status_code != 200:
                print(f"Ø®Ø·Ø£ HTTP Ø¹Ù†Ø¯ Ø¬Ù„Ø¨ {pair}: Ø­Ø§Ù„Ø© {response.status_code}")
                return None
        
            data = response.json()
        
            if 'status' in data and data['status'] == 'error':
                print(f"Ø®Ø·Ø£ Ù…Ù† API Ø¹Ù†Ø¯ Ø¬Ù„Ø¨ {pair}: {data.get('message', 'Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}")
                return None
        
            if 'values' not in data or not data['values']:
                print(f"Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù€ {pair}")
                return None
        
            df = pd.DataFrame(data['values'])
            df['datetime'] = pd.to_datetime(df['datetime'], utc=True) + timedelta(hours=2)  # Convert to Palestine time (UTC+2)
            df = df.sort_values('datetime')
        
            for col in ['open', 'high', 'low', 'close', 'volume']:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
        
            return df
    
        except requests.exceptions.RequestException as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¹Ù†Ø¯ Ø¬Ù„Ø¨ {pair}: {str(e)}")
            return None
        except json.JSONDecodeError as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ ÙÙƒ JSON Ø¹Ù†Ø¯ Ø¬Ù„Ø¨ {pair}: {str(e)}")
            return None
        except Exception as e:
            print(f"Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø¹Ù†Ø¯ Ø¬Ù„Ø¨ {pair}: {str(e)}")
            return None

    #------------------------------------------------------
    def fetch_indicators_data(self, pair, selected_indicators, interval='1min'):
        """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…Ø®ØªØ§Ø±Ø© Ù…Ù† API"""
        indicators_data = {}
        
        for category, indicators in selected_indicators.items():
            if not indicators:  # ØªØ®Ø·ÙŠ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„ÙØ§Ø±ØºØ©
                continue
                
            for indicator in indicators:
                try:
                    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨ÙƒÙ„ Ù…Ø¤Ø´Ø±
                    params = self._get_indicator_params(indicator)
                    
                    # Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¤Ø´Ø±
                    data = self.fetch_indicator_data(pair, indicator, interval, **params)
                    
                    if data:
                        indicators_data[indicator] = data
                        print(f"ØªÙ… Ø¬Ù„Ø¨ {indicator} Ù„Ù€ {pair}")
                    else:
                        print(f"ÙØ´Ù„ Ø¬Ù„Ø¨ {indicator} Ù„Ù€ {pair}")
                    
                    # ØªØ£Ø®ÙŠØ± Ù„ØªØ¬Ù†Ø¨ Ø§Ø³ØªÙ†ÙØ§Ø¯ Ø±ØµÙŠØ¯ API (8 Ø·Ù„Ø¨Ø§Øª ÙÙŠ Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©)
                    import time
                    time.sleep(8)  # 8 Ø«ÙˆØ§Ù†ÙŠ Ø¨ÙŠÙ† ÙƒÙ„ Ø·Ù„Ø¨
                        
                except Exception as e:
                    print(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ {indicator} Ù„Ù€ {pair}: {str(e)}")
                    continue
        
        return indicators_data

    def _get_indicator_params(self, indicator):
        """Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„ÙƒÙ„ Ù…Ø¤Ø´Ø±"""
        default_params = {
            'sma': {'time_period': 20},
            'ema': {'time_period': 20},
            'wma': {'time_period': 20},
            'dema': {'time_period': 20},
            'tema': {'time_period': 20},
            'kama': {'time_period': 20},
            'hma': {'time_period': 20},
            't3': {'time_period': 20},
            'rsi': {'time_period': 14},
            'stoch': {'time_period': 14},
            'stochrsi': {'time_period': 14},
            'willr': {'time_period': 14},
            'macd': {'time_period': 14},
            'ppo': {'time_period': 14},
            'adx': {'time_period': 14},
            'cci': {'time_period': 14},
            'mom': {'time_period': 14},
            'roc': {'time_period': 14},
            'bbands': {'time_period': 20, 'series_type': 'close'},
            'atr': {'time_period': 14},
            'stdev': {'time_period': 20},
            'donchian': {'time_period': 20},
            'obv': {},
            'cmf': {'time_period': 20},
            'ad': {},
            'mfi': {'time_period': 14},
            'emv': {},
            'fi': {'time_period': 14},
            'avgprice': {},
            'medprice': {},
            'typprice': {},
            'wcprice': {},
            'sar': {'time_period': 14},
            'ultosc': {'time_period': 14},
            'tsi': {'time_period': 14}
        }
        
        return default_params.get(indicator, {})

    @staticmethod
    def safe_float(val):
        try:
            if pd.isna(val):
                return None
            return float(val)
        except:
            return None

    def _get_indicator_value(self, data, keys):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø¤Ø´Ø± Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ù…Ø­Ø§ÙˆÙ„Ø© Ù…ÙØ§ØªÙŠØ­ Ù…ØªØ¹Ø¯Ø¯Ø©"""
        if not data or len(data) == 0:
            return None
            
        for key in keys:
            if key in data[0]:
                try:
                    return float(data[0][key])
                except:
                    continue
        return None

    def _get_indicator_values(self, data, keys, count=2):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÙŠÙ… Ù…ØªØ¹Ø¯Ø¯Ø© Ù…Ù† Ø§Ù„Ù…Ø¤Ø´Ø±"""
        if not data or len(data) < count:
            return None
            
        values = []
        for i in range(count):
            for key in keys:
                if key in data[i]:
                    try:
                        values.append(float(data[i][key]))
                        break
                    except:
                        continue
            else:
                return None
        return values

    def analyze_trend_indicators(self, indicators_data, price_data):
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø§ØªØ¬Ø§Ù‡"""
        signals = []
        details = []
        
        if not indicators_data:
            return signals, details
            
        # ØªØ­Ù„ÙŠÙ„ Moving Averages
        for ma_type in ['sma', 'ema', 'wma', 'dema', 'tema', 'kama', 'hma', 't3']:
            if ma_type in indicators_data:
                ma_data = indicators_data[ma_type]
                ma_values = self._get_indicator_values(ma_data, ['value', ma_type, 'sma', 'ema'])
                
                if ma_values and len(ma_values) >= 2:
                    current_ma = ma_values[0]
                    prev_ma = ma_values[1]
                    current_price = float(price_data[0]['close'])
                    
                    # Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ØªØ­Ø±Ùƒ
                    if current_ma > prev_ma:
                        signals.append(0.6)
                        details.append(f"ğŸ“ˆ {ma_type.upper()} ØµØ§Ø¹Ø¯ ({current_ma:.5f})")
                    elif current_ma < prev_ma:
                        signals.append(-0.6)
                        details.append(f"ğŸ“‰ {ma_type.upper()} Ù‡Ø§Ø¨Ø· ({current_ma:.5f})")
                    
                    # Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø³Ø¹Ø± Ù…Ù† Ø§Ù„Ù…ØªÙˆØ³Ø·
                    if current_price > current_ma:
                        signals.append(0.4)
                        details.append(f"ğŸ“Š Ø§Ù„Ø³Ø¹Ø± ÙÙˆÙ‚ {ma_type.upper()}")
                    else:
                        signals.append(-0.4)
                        details.append(f"ğŸ“Š Ø§Ù„Ø³Ø¹Ø± ØªØ­Øª {ma_type.upper()}")
                else:
                    print(f"Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÙŠÙ… {ma_type}")
        
        return signals, details

    def analyze_momentum_indicators(self, indicators_data, price_data):
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø²Ø®Ù…"""
        signals = []
        details = []
        
        if not indicators_data:
            return signals, details
            
        # ØªØ­Ù„ÙŠÙ„ RSI
        if 'rsi' in indicators_data:
            rsi_data = indicators_data['rsi']
            rsi_values = self._get_indicator_values(rsi_data, ['value', 'rsi'])
            
            if rsi_values and len(rsi_values) >= 2:
                current_rsi = rsi_values[0]
                prev_rsi = rsi_values[1]
                
                # ØªØ´Ø¨Ø¹ Ø´Ø±Ø§Ø¡/Ø¨ÙŠØ¹
                if current_rsi < 30:
                    if current_rsi < 20:
                        signals.append(1)
                        details.append(f"âœ… RSI={current_rsi:.1f} (ØªØ´Ø¨Ø¹ Ø¨ÙŠØ¹ Ø´Ø¯ÙŠØ¯)")
                    else:
                        signals.append(0.7)
                        details.append(f"âœ… RSI={current_rsi:.1f} (ØªØ´Ø¨Ø¹ Ø¨ÙŠØ¹)")
                elif current_rsi > 70:
                    if current_rsi > 80:
                        signals.append(-1)
                        details.append(f"âŒ RSI={current_rsi:.1f} (ØªØ´Ø¨Ø¹ Ø´Ø±Ø§Ø¡ Ø´Ø¯ÙŠØ¯)")
                    else:
                        signals.append(-0.7)
                        details.append(f"âŒ RSI={current_rsi:.1f} (ØªØ´Ø¨Ø¹ Ø´Ø±Ø§Ø¡)")
                elif current_rsi > 50 and prev_rsi <= 50:
                    signals.append(0.6)
                    details.append(f"ğŸ“ˆ RSI={current_rsi:.1f} (Ø²Ø®Ù… ØµØ¹ÙˆØ¯ÙŠ)")
                elif current_rsi < 50 and prev_rsi >= 50:
                    signals.append(-0.6)
                    details.append(f"ğŸ“‰ RSI={current_rsi:.1f} (Ø²Ø®Ù… Ù‡Ø¨ÙˆØ·ÙŠ)")
            else:
                print("Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÙŠÙ… RSI")
        
        # ØªØ­Ù„ÙŠÙ„ MACD
        if 'macd' in indicators_data:
            macd_data = indicators_data['macd']
            macd_values = self._get_indicator_values(macd_data, ['value', 'macd'])
            
            if macd_values and len(macd_values) >= 2:
                current_macd = macd_values[0]
                prev_macd = macd_values[1]
                current_signal = self._get_indicator_value(macd_data, ['signal', 'macd_signal'])
                prev_signal = self._get_indicator_value(macd_data[1:], ['signal', 'macd_signal']) if len(macd_data) > 1 else 0
                
                # ØªÙ‚Ø§Ø·Ø¹ MACD Ù…Ø¹ Ø®Ø· Ø§Ù„Ø¥Ø´Ø§Ø±Ø©
                if current_macd > current_signal and prev_macd <= prev_signal:
                    signals.append(1)
                    details.append(f"âœ… MACD Ø¹Ø¨Ø± ÙÙˆÙ‚ Ø®Ø· Ø§Ù„Ø¥Ø´Ø§Ø±Ø©")
                elif current_macd < current_signal and prev_macd >= prev_signal:
                    signals.append(-1)
                    details.append(f"âŒ MACD Ø¹Ø¨Ø± ØªØ­Øª Ø®Ø· Ø§Ù„Ø¥Ø´Ø§Ø±Ø©")
                elif current_macd > current_signal:
                    signals.append(0.5)
                    details.append(f"ğŸ“ˆ MACD Ø¥ÙŠØ¬Ø§Ø¨ÙŠ")
                else:
                    signals.append(-0.5)
                    details.append(f"ğŸ“‰ MACD Ø³Ù„Ø¨ÙŠ")
        
        # ØªØ­Ù„ÙŠÙ„ Stochastic
        if 'stoch' in indicators_data:
            stoch_data = indicators_data['stoch']
            if len(stoch_data) >= 1 and ('k' in stoch_data[0] or 'value' in stoch_data[0]):
                current_k = float(stoch_data[0].get('k', stoch_data[0].get('value', 0)))
                current_d = float(stoch_data[0].get('d', 0))
                
                if current_k < 20:
                    signals.append(0.7)
                    details.append(f"âœ… Stochastic={current_k:.1f} (ØªØ´Ø¨Ø¹ Ø¨ÙŠØ¹)")
                elif current_k > 80:
                    signals.append(-0.7)
                    details.append(f"âŒ Stochastic={current_k:.1f} (ØªØ´Ø¨Ø¹ Ø´Ø±Ø§Ø¡)")
        
        return signals, details

    def analyze_volatility_indicators(self, indicators_data, price_data):
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªØ°Ø¨Ø°Ø¨"""
        signals = []
        details = []
        
        if not indicators_data:
            return signals, details
            
        # ØªØ­Ù„ÙŠÙ„ Bollinger Bands
        if 'bbands' in indicators_data:
            bb_data = indicators_data['bbands']
            if len(bb_data) >= 1 and ('upper_band' in bb_data[0] or 'value' in bb_data[0]):
                current_price = float(price_data[0]['close'])
                upper_band = float(bb_data[0].get('upper_band', bb_data[0].get('value', 0)))
                middle_band = float(bb_data[0].get('middle_band', 0))
                lower_band = float(bb_data[0].get('lower_band', 0))
                
                # Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø³Ø¹Ø± Ù…Ù† Ø§Ù„Ø¨ÙˆÙ„ÙŠÙ†Ø¬Ø±
                if current_price >= upper_band:
                    signals.append(-0.8)
                    details.append(f"âŒ Ø§Ù„Ø³Ø¹Ø± Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø¹Ù„ÙˆÙŠ - Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ø±ØªØ¯Ø§Ø¯")
                elif current_price <= lower_band:
                    signals.append(0.8)
                    details.append(f"âœ… Ø§Ù„Ø³Ø¹Ø± Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø³ÙÙ„ÙŠ - Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ø±ØªØ¯Ø§Ø¯")
                elif current_price > middle_band:
                    signals.append(0.3)
                    details.append(f"ğŸ“Š Ø§Ù„Ø³Ø¹Ø± ÙÙŠ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø¹Ù„ÙŠØ§")
                else:
                    signals.append(-0.3)
                    details.append(f"ğŸ“Š Ø§Ù„Ø³Ø¹Ø± ÙÙŠ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø³ÙÙ„Ù‰")
        
        # ØªØ­Ù„ÙŠÙ„ ATR
        if 'atr' in indicators_data:
            atr_data = indicators_data['atr']
            if len(atr_data) >= 2 and 'value' in atr_data[0] and 'value' in atr_data[1]:
                current_atr = float(atr_data[0]['value'])
                prev_atr = float(atr_data[1]['value'])
                atr_change = ((current_atr - prev_atr) / prev_atr * 100) if prev_atr != 0 else 0
                
                if atr_change > 10:
                    details.append(f"âš ï¸ ATR={current_atr:.5f} (ØªÙ‚Ù„Ø¨ Ù…ØªØ²Ø§ÙŠØ¯ +{atr_change:.1f}%)")
                elif atr_change < -10:
                    details.append(f"ğŸ“Š ATR={current_atr:.5f} (ØªÙ‚Ù„Ø¨ Ù…ØªÙ†Ø§Ù‚Øµ {atr_change:.1f}%)")
                else:
                    details.append(f"ğŸ“Š ATR={current_atr:.5f} (ØªÙ‚Ù„Ø¨ Ù…Ø³ØªÙ‚Ø±)")
        
        return signals, details

    def analyze_volume_indicators(self, indicators_data, price_data):
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø­Ø¬Ù…"""
        signals = []
        details = []
        
        if not indicators_data:
            return signals, details
            
        # ØªØ­Ù„ÙŠÙ„ Money Flow Index
        if 'mfi' in indicators_data:
            mfi_data = indicators_data['mfi']
            if len(mfi_data) >= 1 and 'value' in mfi_data[0]:
                current_mfi = float(mfi_data[0]['value'])
                
                if current_mfi < 20:
                    signals.append(0.7)
                    details.append(f"âœ… MFI={current_mfi:.1f} (ØªØ´Ø¨Ø¹ Ø¨ÙŠØ¹)")
                elif current_mfi > 80:
                    signals.append(-0.7)
                    details.append(f"âŒ MFI={current_mfi:.1f} (ØªØ´Ø¨Ø¹ Ø´Ø±Ø§Ø¡)")
                elif current_mfi > 50:
                    signals.append(0.3)
                    details.append(f"ğŸ“ˆ MFI={current_mfi:.1f} (Ø²Ø®Ù… Ø¥ÙŠØ¬Ø§Ø¨ÙŠ)")
                else:
                    signals.append(-0.3)
                    details.append(f"ğŸ“‰ MFI={current_mfi:.1f} (Ø²Ø®Ù… Ø³Ù„Ø¨ÙŠ)")
        
        # ØªØ­Ù„ÙŠÙ„ Chaikin Money Flow
        if 'cmf' in indicators_data:
            cmf_data = indicators_data['cmf']
            if len(cmf_data) >= 1 and 'value' in cmf_data[0]:
                current_cmf = float(cmf_data[0]['value'])
                
                if current_cmf > 0.1:
                    signals.append(0.5)
                    details.append(f"ğŸ“ˆ CMF={current_cmf:.3f} (ØªØ¯ÙÙ‚ Ø£Ù…ÙˆØ§Ù„ Ø¥ÙŠØ¬Ø§Ø¨ÙŠ)")
                elif current_cmf < -0.1:
                    signals.append(-0.5)
                    details.append(f"ğŸ“‰ CMF={current_cmf:.3f} (ØªØ¯ÙÙ‚ Ø£Ù…ÙˆØ§Ù„ Ø³Ù„Ø¨ÙŠ)")
        
        return signals, details

    def analyze_price_indicators(self, indicators_data, price_data):
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø³Ø¹Ø±"""
        signals = []
        details = []
        
        if not indicators_data:
            return signals, details
            
        # ØªØ­Ù„ÙŠÙ„ Average Price
        if 'avgprice' in indicators_data:
            avgprice_data = indicators_data['avgprice']
            if len(avgprice_data) >= 1:
                current_avg = float(avgprice_data[0]['value'])
                current_close = float(price_data[0]['close'])
                
                if current_close > current_avg:
                    signals.append(0.4)
                    details.append(f"ğŸ“ˆ Ø§Ù„Ø³Ø¹Ø± ÙÙˆÙ‚ Ø§Ù„Ù…ØªÙˆØ³Ø·")
                else:
                    signals.append(-0.4)
                    details.append(f"ğŸ“‰ Ø§Ù„Ø³Ø¹Ø± ØªØ­Øª Ø§Ù„Ù…ØªÙˆØ³Ø·")
        
        return signals, details

    def analyze_misc_indicators(self, indicators_data, price_data):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø®Ø±Ù‰"""
        signals = []
        details = []
        
        if not indicators_data:
            return signals, details
            
        # ØªØ­Ù„ÙŠÙ„ Parabolic SAR
        if 'sar' in indicators_data:
            sar_data = indicators_data['sar']
            if len(sar_data) >= 1:
                current_sar = float(sar_data[0]['value'])
                current_close = float(price_data[0]['close'])
                
                if current_close > current_sar:
                    signals.append(0.6)
                    details.append(f"ğŸ“ˆ SAR={current_sar:.5f} (Ø¥Ø´Ø§Ø±Ø© ØµØ¹ÙˆØ¯)")
                else:
                    signals.append(-0.6)
                    details.append(f"ğŸ“‰ SAR={current_sar:.5f} (Ø¥Ø´Ø§Ø±Ø© Ù‡Ø¨ÙˆØ·)")
        
        # ØªØ­Ù„ÙŠÙ„ Ultimate Oscillator
        if 'ultosc' in indicators_data:
            ultosc_data = indicators_data['ultosc']
            if len(ultosc_data) >= 1:
                current_ultosc = float(ultosc_data[0]['value'])
                
                if current_ultosc < 30:
                    signals.append(0.7)
                    details.append(f"âœ… Ultimate={current_ultosc:.1f} (ØªØ´Ø¨Ø¹ Ø¨ÙŠØ¹)")
                elif current_ultosc > 70:
                    signals.append(-0.7)
                    details.append(f"âŒ Ultimate={current_ultosc:.1f} (ØªØ´Ø¨Ø¹ Ø´Ø±Ø§Ø¡)")
        
        return signals, details
    #--------------------------------------------------
    def train_ai_models(self, pair, historical_data):
        """ØªØ¯Ø±ÙŠØ¨ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
        try:
            if not historical_data or len(historical_data) < 100:
                print(f"Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„Ù€ {pair}")
                return False
            
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
            price_data = []
            indicators_data = {}
            
            for data_point in historical_data:
                price_data.append({
                    'open': float(data_point.get('open', 0)),
                    'high': float(data_point.get('high', 0)),
                    'low': float(data_point.get('low', 0)),
                    'close': float(data_point.get('close', 0))
                })
            
            # ØªØ­Ø¶ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
            features, labels = self.ai_system.prepare_training_data(price_data, indicators_data)
            
            if features is None or len(features) < 50:
                print(f"Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨ ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„Ù€ {pair}")
                return False
            
            # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
            print(f"ğŸ¤– Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„Ù€ {pair}...")
            
            # ØªØ¯Ø±ÙŠØ¨ Ù†Ù…Ø§Ø°Ø¬ ML
            ml_success = self.ai_system.train_ml_models(features, labels)
            
            # ØªØ¯Ø±ÙŠØ¨ Ù†Ù…Ø§Ø°Ø¬ Neural Networks
            lstm_success = self.ai_system.train_lstm_model(features, labels)
            cnn_success = self.ai_system.train_cnn_model(features, labels)
            
            # Ø­ÙØ¸ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
            self.ai_system.save_models()
            
            print(f"âœ… ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„Ù€ {pair} - ML: {ml_success}, LSTM: {lstm_success}, CNN: {cnn_success}")
            return True
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„Ù€ {pair}: {e}")
            return False

    def generate_signal(self, indicators_data, price_data, selected_indicators):
        """ØªÙˆÙ„ÙŠØ¯ Ø¥Ø´Ø§Ø±Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ù…Ø¹ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
        if not indicators_data or not price_data:
            return {
                'signal': 'HOLD',
                'confidence': 0,
                'reason': 'Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ©',
                'indicators': {},
                'ai_prediction': None
            }

        all_signals = []
        all_details = []

        # ØªØ­Ù„ÙŠÙ„ ÙƒÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ø¤Ø´Ø±Ø§Øª
        for category, indicators in selected_indicators.items():
            if not indicators:  # ØªØ®Ø·ÙŠ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„ÙØ§Ø±ØºØ©
                continue

            category_indicators = {ind: indicators_data.get(ind, []) for ind in indicators if ind in indicators_data}

            if category == 'trend':
                signals, details = self.analyze_trend_indicators(category_indicators, price_data)
                all_signals.extend(signals)
                all_details.extend(details)
            elif category == 'momentum':
                signals, details = self.analyze_momentum_indicators(category_indicators, price_data)
                all_signals.extend(signals)
                all_details.extend(details)
            elif category == 'volatility':
                signals, details = self.analyze_volatility_indicators(category_indicators, price_data)
                all_signals.extend(signals)
                all_details.extend(details)
            elif category == 'volume':
                signals, details = self.analyze_volume_indicators(category_indicators, price_data)
                all_signals.extend(signals)
                all_details.extend(details)
            elif category == 'price':
                signals, details = self.analyze_price_indicators(category_indicators, price_data)
                all_signals.extend(signals)
                all_details.extend(details)
            elif category == 'misc':
                signals, details = self.analyze_misc_indicators(category_indicators, price_data)
                all_signals.extend(signals)
                all_details.extend(details)

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
        ai_prediction = None
        if self.ai_enabled and (self.ai_system.ml_models or self.ai_system.neural_models):
            try:
                # Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªÙ†Ø¨Ø¤
                current_features = []
                current_price = price_data[0]
                current_features.extend([
                    current_price['open'],
                    current_price['high'],
                    current_price['low'],
                    current_price['close']
                ])
                
                # Ø¥Ø¶Ø§ÙØ© Ù‚ÙŠÙ… Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
                for category, indicators in selected_indicators.items():
                    for indicator in indicators:
                        if indicator in indicators_data and indicators_data[indicator]:
                            indicator_value = self.ai_system._extract_indicator_value(indicators_data[indicator][0])
                            current_features.append(indicator_value if indicator_value is not None else 0)
                        else:
                            current_features.append(0)
                
                # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙ†Ø¨Ø¤ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
                ai_prediction = self.ai_system.predict_with_ensemble(current_features)
                
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· ÙÙŠ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
                chart_analysis = self.ai_system.analyze_chart_patterns(price_data)
                ai_prediction['chart_patterns'] = chart_analysis
                
                # ØªÙ†Ø¨Ø¤ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø¹Ø²Ø²
                state_vector = current_features[:10]  # Ø£ÙˆÙ„ 10 Ù‚ÙŠÙ… ÙƒØ­Ø§Ù„Ø©
                rl_prediction = self.ai_system.get_reinforcement_prediction(state_vector)
                ai_prediction['reinforcement_learning'] = rl_prediction
                
            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¨Ø¤ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ: {e}")
                ai_prediction = {
                    'signal': 'HOLD',
                    'confidence': 0,
                    'probabilities': {'BUY': 0, 'SELL': 0, 'HOLD': 100},
                    'ensemble_used': False
                }

        # Ø¯Ù…Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠØ© Ù…Ø¹ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
        traditional_avg = np.mean(all_signals) if all_signals else 0
        threshold = 0.35
        
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ø¯ÙŠÙ†Ø§ ØªÙ†Ø¨Ø¤ Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŒ Ù†Ø¯Ù…Ø¬Ù‡ Ù…Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠØ©
        if ai_prediction and ai_prediction.get('ensemble_used', False):
            ai_signal = ai_prediction['signal']
            ai_confidence = ai_prediction['confidence']
            
            # Ø¯Ù…Ø¬ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª (ÙˆØ²Ù† 70% Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŒ 30% Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠ)
            if ai_signal == 'BUY':
                ai_weight = 0.7
                traditional_weight = 0.3
                final_signal = 'CALL'
                signal_text = f'ØµØ¹ÙˆØ¯ (CALL) ğŸ¤– AI: {ai_confidence:.1f}%'
                confidence = ai_confidence * ai_weight + abs(traditional_avg) * 100 * traditional_weight
            elif ai_signal == 'SELL':
                ai_weight = 0.7
                traditional_weight = 0.3
                final_signal = 'PUT'
                signal_text = f'Ù‡Ø¨ÙˆØ· (PUT) ğŸ¤– AI: {ai_confidence:.1f}%'
                confidence = ai_confidence * ai_weight + abs(traditional_avg) * 100 * traditional_weight
            else:
                final_signal = 'HOLD'
                signal_text = f'Ø§Ù†ØªØ¸Ø§Ø± (HOLD) ğŸ¤– AI: {ai_confidence:.1f}%'
                confidence = ai_confidence
        else:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠ ÙÙ‚Ø·
            confidence = min(abs(traditional_avg) * 100, 100)
            
            if traditional_avg > threshold:
                final_signal = 'CALL'
                signal_text = 'ØµØ¹ÙˆØ¯ (CALL) ğŸŸ¢'
            elif traditional_avg < -threshold:
                final_signal = 'PUT'
                signal_text = 'Ù‡Ø¨ÙˆØ· (PUT) ğŸ”´'
            else:
                final_signal = 'HOLD'
                signal_text = 'Ø§Ù†ØªØ¸Ø§Ø± (HOLD) âšª'

        # Ø¬Ù…Ø¹ Ù‚ÙŠÙ… Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
        indicators_values = {}
        for category, indicators in selected_indicators.items():
            for indicator in indicators:
                if indicator in indicators_data and indicators_data[indicator]:
                    latest_data = indicators_data[indicator][0]
                    if isinstance(latest_data, dict):
                        for key, value in latest_data.items():
                            if key != 'datetime':
                                indicators_values[f"{indicator}_{key}"] = self.safe_float(value)

        # Ø¥Ø¶Ø§ÙØ© ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
        ai_details = []
        if ai_prediction:
            if ai_prediction.get('probabilities'):
                ai_details.append(f"ğŸ¤– AI Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª: BUY {ai_prediction['probabilities'].get('BUY', 0):.1f}%, SELL {ai_prediction['probabilities'].get('SELL', 0):.1f}%, HOLD {ai_prediction['probabilities'].get('HOLD', 0):.1f}%")
            
            if ai_prediction.get('chart_patterns', {}).get('patterns_detected'):
                patterns = ai_prediction['chart_patterns']['patterns_detected']
                ai_details.append(f"ğŸ“Š Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø±Ø³Ù…: {', '.join(patterns)}")
            
            if ai_prediction.get('reinforcement_learning', {}).get('signal'):
                rl_signal = ai_prediction['reinforcement_learning']['signal']
                rl_conf = ai_prediction['reinforcement_learning']['confidence']
                ai_details.append(f"ğŸ§  Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø¹Ø²Ø²: {rl_signal} ({rl_conf:.1f}%)")

        # Ø¯Ù…Ø¬ Ø§Ù„ØªÙØ§ØµÙŠÙ„
        all_details.extend(ai_details)

        return {
            'signal': final_signal,
            'signal_text': signal_text,
            'confidence': round(confidence, 1),
            'reason': ' | '.join(all_details[:4]) if all_details else 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø´Ø§Ø±Ø§Øª',
            'all_details': all_details,
            'indicators': indicators_values,
            'price': {
                'open': self.safe_float(price_data[0]['open']),
                'high': self.safe_float(price_data[0]['high']),
                'low': self.safe_float(price_data[0]['low']),
                'close': self.safe_float(price_data[0]['close'])
            },
            'last_candle_time': price_data[0]['datetime'],
            'ai_prediction': ai_prediction,
            'ai_enabled': self.ai_enabled
        }
    def analyze_pair(self, pair, period, selected_indicators, interval='1min'):
        """ØªØ­Ù„ÙŠÙ„ Ø²ÙˆØ¬ ÙˆØ§Ø­Ø¯"""
        try:
            # Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø¹Ø§Ø±
            price_df = self.fetch_price_data(pair, interval, period)
            if price_df is None or len(price_df) == 0:
                print(f"Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø³Ø¹Ø§Ø± Ù„Ù€ {pair}")
                return None

            # Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
            indicators_data = self.fetch_indicators_data(pair, selected_indicators, interval)
            if not indicators_data:
                print(f"Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¤Ø´Ø±Ø§Øª Ù„Ù€ {pair}")
                return None

            # ØªØ­ÙˆÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ Ù…Ù†Ø§Ø³Ø¨
            price_data = []
            for _, row in price_df.tail(50).iterrows():
                price_data.append({
                    'datetime': row['datetime'].strftime('%Y-%m-%d %H:%M:%S'),
                    'open': self.safe_float(row['open']),
                    'high': self.safe_float(row['high']),
                    'low': self.safe_float(row['low']),
                    'close': self.safe_float(row['close'])
                })

            if not price_data:
                print(f"Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø¹Ø§Ø± ÙØ§Ø±ØºØ© Ù„Ù€ {pair}")
                return None

            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©
            analysis = self.generate_signal(indicators_data, price_data, selected_indicators)
            
            # Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ù…ÙˆØ¹ Ù„Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
            chart_data = []
            for row in price_data:
                chart_data.append({
                    'time': row['datetime'].split(' ')[1][:5],  # Ø§Ù„ÙˆÙ‚Øª ÙÙ‚Ø·
                    'open': row['open'],
                    'high': row['high'],
                    'low': row['low'],
                    'close': row['close']
                })
            analysis['chart_data'] = chart_data
            return analysis
            
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ {pair}: {str(e)}")
            return None
    def start_analysis(self, pairs, period, interval_minutes, selected_indicators):
        """ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¯ÙˆÙ† ØªØ´ØºÙŠÙ„ ØªØ­Ù„ÙŠÙ„ Ù…Ø³ØªÙ…Ø±"""
        self.latest_results = {}  # Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        self.is_running = True
        self.analysis_config = {
            'pairs': pairs,
            'period': period,
            'interval': interval_minutes,
            'indicators': selected_indicators
        }
        return True


    def stop_analysis(self):
        """Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
        self.is_running = False
        if self.analysis_thread:
            self.analysis_thread.join(timeout=2)
        return True

load_dotenv()
API_KEY = os.getenv("TWELVEDATA_API_KEY")
analyzer = TradingAnalyzer(API_KEY)

app = Flask(__name__)

CORS(app)

@app.route('/')
def index():
    """Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    return render_template('index.html')

@app.route('/api/pairs')
def get_pairs():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø©"""
    return jsonify(analyzer.available_pairs)

@app.route('/api/indicators')
def get_indicators():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©"""
    return jsonify(analyzer.available_indicators)

@app.route('/api/config', methods=['POST'])
def set_config():
    """ØªØ¹ÙŠÙŠÙ† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª API"""
    data = request.json
    analyzer.set_api_key(data.get('api_key', ''))
    return jsonify({'status': 'success'})

@app.route('/api/start', methods=['POST'])
def start_analysis():
    """Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
    data = request.json
    pairs = data.get('pairs', [])
    period = data.get('period', 250)
    interval = data.get('interval', 1)
    selected_indicators = data.get('indicators', ['RSI', 'MACD'])
    
    if analyzer.start_analysis(pairs, period, interval, selected_indicators):
        return jsonify({'status': 'success', 'message': 'ØªÙ… Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„'})
    else:
        return jsonify({'status': 'error', 'message': 'Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙŠØ¹Ù…Ù„ Ø¨Ø§Ù„ÙØ¹Ù„'})

@app.route('/api/stop', methods=['POST'])
def stop_analysis():
    """Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
    if analyzer.stop_analysis():
        return jsonify({'status': 'success', 'message': 'ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ­Ù„ÙŠÙ„'})
    else:
        return jsonify({'status': 'error', 'message': 'ÙØ´Ù„ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ­Ù„ÙŠÙ„'})

@app.route('/api/status')
def get_status():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
    return jsonify({
        'is_running': analyzer.is_running,
        'results': analyzer.latest_results
    })

@app.route('/api/requests-status')
def get_requests_status():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø·Ù„Ø¨Ø§Øª API"""
    return jsonify(analyzer.get_api_status())

@app.route('/api/ai/train', methods=['POST'])
def train_ai_models():
    """ØªØ¯Ø±ÙŠØ¨ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
    try:
        data = request.json
        pair = data.get('pair', 'EUR/USD')
        period = data.get('period', 500)
        
        # Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨
        price_df = analyzer.fetch_price_data(pair, '1min', period)
        if price_df is None:
            return jsonify({'status': 'error', 'message': 'ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©'})
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        historical_data = []
        for _, row in price_df.iterrows():
            historical_data.append({
                'open': row['open'],
                'high': row['high'],
                'low': row['low'],
                'close': row['close']
            })
        
        # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
        success = analyzer.train_ai_models(pair, historical_data)
        
        if success:
            return jsonify({
                'status': 'success', 
                'message': f'ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ù†Ø¬Ø§Ø­ Ù„Ù€ {pair}',
                'metrics': analyzer.ai_system.get_performance_metrics()
            })
        else:
            return jsonify({'status': 'error', 'message': 'ÙØ´Ù„ ÙÙŠ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬'})
            
    except Exception as e:
        return jsonify({'status': 'error', 'message': f'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {str(e)}'})

@app.route('/api/ai/status')
def get_ai_status():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
    try:
        metrics = analyzer.ai_system.get_performance_metrics()
        return jsonify({
            'status': 'success',
            'ai_enabled': analyzer.ai_enabled,
            'metrics': metrics
        })
    except Exception as e:
        return jsonify({'status': 'error', 'message': f'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© AI: {str(e)}'})

@app.route('/api/ai/toggle', methods=['POST'])
def toggle_ai():
    """ØªÙØ¹ÙŠÙ„/Ø¥Ù„ØºØ§Ø¡ ØªÙØ¹ÙŠÙ„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
    try:
        data = request.json
        enabled = data.get('enabled', True)
        analyzer.ai_enabled = enabled
        
        return jsonify({
            'status': 'success',
            'message': f'ØªÙ… {"ØªÙØ¹ÙŠÙ„" if enabled else "Ø¥Ù„ØºØ§Ø¡ ØªÙØ¹ÙŠÙ„"} Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ',
            'ai_enabled': analyzer.ai_enabled
        })
    except Exception as e:
        return jsonify({'status': 'error', 'message': f'Ø®Ø·Ø£ ÙÙŠ ØªØºÙŠÙŠØ± Ø­Ø§Ù„Ø© AI: {str(e)}'})

@app.route('/api/ai/performance')
def get_ai_performance():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
    try:
        performance = analyzer.ai_system.get_performance_metrics()
        return jsonify({
            'status': 'success',
            'performance': performance
        })
    except Exception as e:
        return jsonify({'status': 'error', 'message': f'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø¡: {str(e)}'})


@app.route('/api/results')
def get_results():
    """ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¹Ù†Ø¯ Ø§Ù„Ø·Ù„Ø¨"""
    try:
        if not analyzer.is_running or not hasattr(analyzer, 'analysis_config'):
            return jsonify({'status': 'error', 'message': 'Ø§Ù„ØªØ­Ù„ÙŠÙ„ ØºÙŠØ± Ù…ÙØ¹Ù„ Ø­Ø§Ù„ÙŠØ§Ù‹'})

        config = analyzer.analysis_config
        results = {}
        current_time = datetime.now(timezone.utc) + timedelta(hours=2)

        for pair in config['pairs']:
            try:
                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙØªØ±Ø© Ø¥Ù„Ù‰ Ø¯Ù‚Ø§Ø¦Ù‚
                interval_str = f"{config['interval']}min"
                analysis = analyzer.analyze_pair(
                    pair,
                    config['period'],
                    config['indicators'],
                    interval_str
                )
                if analysis:
                    next_candle = current_time.replace(second=0, microsecond=0) + timedelta(minutes=1)
                    end_time = next_candle + timedelta(minutes=config['interval'])

                    analysis['trade_timing'] = {
                        'current_time': current_time.strftime('%Y-%m-%d %H:%M:%S'),
                        'entry_time': next_candle.strftime('%H:%M:%S'),
                        'exit_time': end_time.strftime('%H:%M:%S'),
                        'duration': config['interval']
                    }

                    results[pair] = analysis
                else:
                    print(f"ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ {pair}")
            except Exception as e:
                print(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ {pair}: {str(e)}")
                continue

        analyzer.latest_results = {
            'timestamp': datetime.now().isoformat(),
            'analysis': results,
            'selected_indicators': config['indicators'],
            'status': 'success'
        }
        return jsonify(analyzer.latest_results)
        
    except Exception as e:
        print(f"Ø®Ø·Ø£ ÙÙŠ API results: {str(e)}")
        return jsonify({'status': 'error', 'message': f'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…: {str(e)}'})
if __name__ == '__main__':
    print("ğŸš€ Ø¨Ø¯Ø¡ Ø®Ø§Ø¯Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…...")
    print("ğŸ“± Ø§ÙØªØ­ Ø§Ù„Ù…ØªØµÙØ­ Ø¹Ù„Ù‰: http://localhost:5000")
    print("ğŸ“Š Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:")
    print("   ğŸ”„ Trend: SMA, EMA, WMA, DEMA, TEMA, KAMA, HMA, T3")
    print("   âš¡ Momentum: RSI, STOCH, STOCHRSI, WILLR, MACD, PPO, ADX, CCI, MOM, ROC")
    print("   ğŸ“ˆ Volatility: BBANDS, ATR, STDEV, DONCHIAN")
    print("   ğŸ“Š Volume: OBV, CMF, AD, MFI, EMV, FI")
    print("   ğŸ’° Price: AVGPRICE, MEDPRICE, TYPPRICE, WCPRICE")
    print("   ğŸ¯ Misc: SAR, ULTOSC, TSI")
    app.run(debug=True, host='0.0.0.0', port=5000)